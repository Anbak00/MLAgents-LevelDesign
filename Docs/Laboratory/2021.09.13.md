
# 목표
게임 인공지능을 게임 난이도에 맞춰 학습시키는 방법론
예시: 
1.	오델로: 
2.	바둑: 게임 난이도를 높일수록 인공지능이 외통수를 사용하기 시작한다. 평범하게 좋은 수를 두는 능력이 향상된다.
3.	체스: 
4.	로스트아크: 
5.	철권: 게임 난이도를 높일수록 인공지능이 플레이어의 공격을 카운터 치고 페이크를 걸기 시작한다. 공격의 예리함과 콤보 능력이 향상된다.
6.	배틀그라운드: 게임 난이도를 높일수록 인공지능이 장비를 파밍하는 실력과 유리한 장소를 선점하기 시작한다. 사격 능력과 수류탄을 활용하는 등의 전술 전략 능력이 향상된다.
# 사용프로그램: 
Unity + ML-Agents
인공지능과 알고리즘의 차이점: 
1.	알고리즘은 패턴을 외우는 것으로 파훼해야 한다. 
2.	인공지능은 수싸움을 통해 파훼해야 한다
# 전제1:
1.	사람이 인공지능을 이길 수 있어야 한다
2.	이기는 과정이 재밌어야 한다
3.	인공지능이 사람에게 일부러 져선 안 된다
# 전제2:
1.	Agent는 플레이어에게 패배했을 때만 보상을 받을 수 있도록 한다
A.	플레이어의 실력이 Agent의 난이도보다 부족한 경우 플레이어가 패배할 수 있다.
2.	보상의 크기는 Agent가 게임 속 기술을 많이 사용할수록 커지도록 한다
A.	자신의 수준에 맞는 난이도를 선택한 플레이어는 Agent의 공격을 파훼할 수 있어야 한다. 파훼하지 못하면 데미지를 입고 진다
3.	1에서 Agent가 의도적으로 패배했을 땐 처벌을 받도록 한다
A.	Agent가 장기간 행동하지 않는 경우
 
(학습횟수 320,000) 골을 먹히면 처벌을 받고 골을 넣으면 보상을 받는데 Agent들이 공을 건드리지 않고 자신의 골대만 지키고 있다. 현재 처벌의 강도가 보상의 강도보다 크다. 꽤 자주 자살골을 넣는데 왜 그러는지 모르겠다.
(예제) 공을 잘 찬다. 골인시키려고 노력하며 막으려고도 노력한다. 그러나 자주 공을 놓치는 등의 어설픈 모습이 자주 보인다. 
B.	Agent가 자신의 패배조건을 스스로 달성한 경우
C.	Agent가 사용한 기술이 Player에게 위협을 가하지 못한 경우
# 문제점:
1.	전제2에서 학습하기 위해선 플레이어가 필요하다. 다만 그런 경우 학습에 걸리는 시간이 매우 크다.
2.	전제2의 2는 게임의 종류가 다양하기에 게임 속 기술이 무엇인지 하나로 정의할 수 없다
3.	전제2의 3은 인공지능이 외통수와 심리전을 사용하는 것을 제한할 수 있다. 
# 방법론:
1.	리워드를 제공하는 시점을 조정하는 방법론
A.	플레이어 입장에서 파훼하기 힘든 기술을 사용하는데 큰 리워드를 제공하면 그 결과로 나오는 에이전트의 난이도는 하드일 것이다
B.	결국 플레이어가 승리해야만 리워드를 받을 수 있다
i.	플레이어가 치열하게 승리할수록 큰 리워드를 받는다
C.	학습한 에이전트를 플레이어로 가정하고 다시 에이전트를 학습시키는 방법
D.	그냥 처음부터 학습시키는 방법
2.	Agent Reward Function (dependent):
A.	Accumulated reward When players ball enters opponent's goal accumulated reward is incremented by using one skills.
B.	-1 reward When suicide goal of agent
3.	학습횟수를 척도로 삼는 방법론
A.	학습횟수에 따라서 에이전트의 지능이 달라진다
B.	문제점은 세부 조정없이 단순히 학습횟수가 낮으면 에이전트가 멍청하고 단순히 학습횟수가 높으면 에이전트가 완벽해지기 때문에 재미요소가 떨어진다
i.	이용환 지도교수님께서 지적해주신 문제
# 대안:
1.	PlayeVSAgent 구도에서 학습하는 것 대신 AgentVSAgent로 학습시키는 것을 고려해볼 수 있다. 
학습횟수: 

# 다음 과제:
 기술 만들기
1.	기본 조작으로 유동적으로 구현되는 기술 만들고 적용해보기
2.	알고리즘으로 수동적으로 구현되는 기술 만들기 적용해보기
